# 存储系统  
---
## 存储器概述  
### 存储器的分类  
存储器种类繁多，可以从不同角度对存储器进行分类。  
+ 按在计算机中的作用（层次）分类  
  - 主存储器。简称主存，又称内存储器（内存），用来存放计算机运行期间所需的大量程序和数据，CPU可以直接随机地对其进行访问，也可以和高速缓冲存储器（Cache）及辅助存储器交换数据。其特点是容量小、存取速度较快、每位价格较高。  
  - 辅助存储器。简称辅存，又称外存储器（外存），是主存储器的后援存储器，用来存放当前暂时不用的程序和数据，以及一些需要永久性保存的信息，**它不能与CPU直接交换信息**。其特点是容量极大、存取速度较慢、单位成本低。  
  - 高速缓冲存储器。简称Cache，位于主存和CPU之间，用来存放正在执行的程序段和数据，以便CPU能够高速地使用它们。Cache的存取速度可与CPU的速度相匹配，但存储容量小、价格高。目前的高档计算机通常把它们制作在CPU中。  
+ 按存储介质分类  
按存储介质，存储器可分为磁表面存储器（磁盘、磁带）、磁心存储器半导体存储器（MOS型存储器、双极型存储器）和光存储器（光盘）。  
+ 按存取方式分类  
  - 随机存储器RAM。存储器的任何一个存储单元的内容都可以随机存取，而且存取时间与存储单元的物理位置无关。其优点是读写方便、使用灵活，主要用作主存或高速缓冲存储器。RAM可分为静态RAM（以触发器原理寄存信息）和动态RAM（以电容充电原理寄存信息）。  
  - 只读存储器ROM。存储器的内容只能随机读出而不能写入。信息一旦写入存储器就固定不变，即使断电，内容也不会丢失。因此，通常用它存放固定不变的程序、常数和汉字字库，甚至用于操作系统的固化。**它与随机存储器可共同作为主存的一部分，统一构成主存的地址域**。  
  由ROM派生出的存储器也包含可反复重写的类型，ROM和RAM的存取方式均为随机存取。广义上的只读存储器已可通过电擦除等方式进行写入，其“只读”的概念没有保留，但仍然保留了断电内容保留、随机读取特性，但其写入速度比读取速度慢得多。  
  - 串行访问存储器。对存储单元进行读/写操作时，需按其物理位置的先后顺序寻址，包括顺序存取存储器（如磁带）与直接存取存储器（如磁盘）。  
  顺序存取存储器的内容只能按某种顺序存取，存取时间的长短与信息在存储体上的物理位置有关，其特点是存取速度慢。直接存取存储器既不像RAM那样随机地访问任何一个存储单元，又不像顺序存取存储器那样完全按顺序存取，而是介于两者之间。存取信息时通过先寻找整个存储器中的某个小区域（如磁盘上的磁道），再在小区域内顺序查找。  
+ 按信息的可保存性分类  
断电后，存储信息即消失的存储器，称为易失性存储器，如RAM。断电后信息仍然保持的存储器，称为非易失性存储器，如ROM、磁表面存储器和光存储器。若某个存储单元所存储的信息被读出时，原存储信息被破坏，则称为破坏性读出；若读出时，被读单元原存储信息不被破坏，则称为非破坏性读出。具有破坏性读出性能的存储器，每次读出操作后，必须紧接一个再生的操作，以便恢复被破坏的信息。  
### 存储器的性能指标  
存储器有3个主要想性能指标，即存储容量、单位成本和存储速度。这三个指标相互制约，设计存储器系统所追求的目标就是大容量、低成本和高速度。  
+ 存储容量=存储字数×字长。存储字数表示存储器的地址空间大小，字长表示一次存储操作的数据量 
+ 单位成本。每位价格=总成本/总容量  
+ 存储速度。数据传输率=数据的宽度/存储周期  
  - 存取时间(T<sub>a</sub>)：存取时间是指从启动一次存储器操作到完成该操作所经历的时间，分为读出时间和写入时间。  
  - 存取周期(T<sub>m</sub>)：存取周期又称读写周期或访问周期。它是指存储器进行一次完整的读写操作所需的全部时间，即连续两次独立访问存储器操作（读或写操作）之间所需要的最小时间间隔。  
  - 主存带宽(B<sub>m</sub>)：主存带宽又称数据传输率，表示每秒从主存进出的信息的最大数量，单位为字/秒、字节/秒或位/秒。  

**存取时间不等于存储周期，通常存储周期大于存取时间。这是因为对任何一种存储器，在读写操作之后，总要有一段恢复内部状态的复原时间。** 对于破坏性读出的存储器，存储周期往往比存取时间大得多，甚至可达T<sub>m</sub>=2T<sub>a</sub>，因为存储器中的信息读出后需要马上进行再生。  

---  
## 存储器的层次化结构  
### 多级存储系统  
为了解决存储系统大容量、高速度和低成本3个相互制约的矛盾，在计算机系统中，通常采用多级存储器结构。  
实际上，存储系统层次结构主要体现在“Cache-主存”层次和“主存-辅存”层次。前者主要解决CPU和主存速度不匹配的问题，后者主要解决存储系统的容量问题。在存储体系中，Cache、主存能与CPU直接交换信息，辅存则要通过主存与CPU交换信息；主存与CPU、Cache、辅存都能交换信息。  
存储器层次结构的思想主要上一层的存储器作为低一层存储器的高速缓存。从CPU的角度看，“Cache-主存”层次速度接近于Cache，容量和价格却接近于主存。从“主存-辅存”层次分析，其速度接近于主存，容量和价格却接近于辅存。这就解决了速度、容量、成本这三者之间的矛盾，现代计算机系统几乎都采用这种三级存储系统。需要注意的是，**主存和Cache之间的数据调动是由硬件自动完成的，对所有程序员均是透明的；而主存和辅存之间的数据调动则是由硬件和操作系统共同完成的，对应用程序员是透明的。**  
在“主存-辅存”这一层次的不断发展中，逐渐形成了虚拟存储系统，在这个系统中程序员编程的地址范围与虚拟存储器的地址空间相对应。对具有虚拟存储器的计算机系统而言，编程时可用的地址空间远大于主存空间。  

---  
## 半导体随机存储器  
主存储器由DRAM实现，靠处理器的那一层（Cache）则由SRAM实现，它们都属于易失性存储器，只要电源被切断，原来保存的信息便会丢失。DRAM的每比特成本低于SRAM，速度也慢于SRAM，价格差异主要是因为制作DRAM需要更多的硅。而ROM属于非易失性存储器。  
### SRAM和DRAM  
#### SRAM的工作原理  
通常把存放一个二进制的物理器件称为存储元，它是存储器的最基本的构件。地址码相同的多个存储元构成一个存储单元。若干存储单元的集合构成存储体。静态随机存储器SRAM的存储元是用双稳态触发器（六晶体管MOS）来记忆信息的，因此即使信息被读出后，它仍保持其原状态而不需要再生（非破坏性读出）。  
SRAM的存取速度快，但集成度低，功耗较大，所以一般用来组成高速缓冲存储器。  
#### DRAM的工作原理  
与SRAM的存储原理不同，动态随机存储器（DRAM）是利用存储元电路中栅极电容上的电荷来存储信息的，DRAM的基本存储元通常只使用一个晶体管，所以它比SRAM的密度要高很多。DRAM采用地址复用技术，地址线是原来的1/2，且地址信号分行、列两次传送。  
相对于SRAM来说，DRAM具有容易集成、位价低、容量大和功耗低等优点，但DRAM的存取速度比SRAM的慢，一般用来组成大容量主存系统。  
DRAM电容上的电荷一般只能维持1-2ms，因此即使电源不断电，信息也会自动消失。为此，每隔一定时间必须刷新，通常取2ms，这个时间称为刷新周期。常用的刷新方式有3种：集中刷新、分散刷新和异步刷新。  
+ 集中刷新：指在一个刷新周期内，利用一段固定的时间，依次对存储器的所有行进行逐一再生，在此期间停止对存储器的读写操作，称为“四时间”，又称访存“死区”。  
集中刷新的优点是读写操作不受刷新工作的影响，因此系统的存取速度较高；缺点是在集中刷新期间（死区）不能访问存储器。  
+ 分散刷新：把对每行的刷新分散到各个工作周期中。这样，一个存储器的系统工作周期分为两部分：前半部分用于正常读、写或保持；后半部分用于刷新某一行。这种刷新方式增加了系统的存取周期。  
分散刷新的优点是没有死区；缺点是加长了系统的存取周期，降低了整机的速度。  
+ 异步刷新：异步刷新是前两种方法的结合，它既可缩短“死时间”，又能充分利用最大刷新间隔2ms的特点。具体做法是将刷新周期除以行数，得到两次刷新操作之间的时间间隔t，利用逻辑电路每隔时间t产生一次刷新请求。这样可以避免使CPU连续等待过长的时间，而且减少了刷新次数，从根本上提高了整机的工作效率。  
**若将刷新安排在不需要访问存储器的译码阶段，则既不会加长存取周期，又不会产生“死时间”，这事分散刷新方式的发展，也称为“透明刷新”**。  

DRAM的刷新需要注意以下问题：  
+ 刷新对CPU是透明的，即刷新不依赖于外部的访问。  
+ 动态RAM的刷新单位是行，因此刷新操作时仅需要行地址。  
+ 刷新操作类似于读操作，但又有所不同。刷新操作仅给栅极电容补充电荷，不需要信息输出。另外，刷新时不需要选片，即整个存储器中所有芯片同时被刷新。  

#### 存储器的读、写周期  
1. RAM的读周期  
从给出有效地址开始，到读出所选中单元的内容并在外部数据总线上稳定地出现所需的时间，称为读出时间（t<sub>A</sub>）。地址片选信号CS必须保持到数据稳定输出，t<sub>CO</sub>为片选的保持时间，在读周期中WE为高电平。  
读周期和读出时间是两个不同的概念，读周期（t<sub>RC</sub>）表示存储芯片进行两次连续读操作时必须间隔的时间，它总是大于等于读出时间。  
1. RAM的写周期  
要实现写操作，要求片选信号CS和写命令WE必须都为低电平。为使数据总线上的信息能够可靠地写入存储器，要求CS信号与WE信号相“与”的宽度至少为t<sub>W</sub>。  
为了保证在地址变化期间不会发生错误写入而破坏存储器的内容，WE信号在地址变化器件必须为高电平。为了保证有效数据的可靠写入，地址有效的时间至少应为t<sub>WC</sub>=t<sub>AW</sub>+t<sub>W</sub>+t<sub>WR</sub>。为了保证在WE和CS变为无效前能把数据可靠地写入，要求写入的数据必须在t<sub>DW</sub>以前在数据总线上已经稳定。  

### 只读存储器  
#### 只读存储器ROM的特点  
ROM和RAM都是支持随机存储器的存储器，其中SRAM和DRAM均为易失性半导体存储器。而ROM中一旦有了信息，就不能轻易改变，即使掉电也不会丢失，它在计算机系统中是只供读出的存储器。ROM器件有两个显著的优点：  
+ 结构简单，所以位密度比可读写存储器的高  
+ 具有非易失性，所以可靠性高  
#### ROM的类型  
根据制作工艺的不同，ROM可分为掩模式只读存储器MROM、一次可编程只读存储器PROM、可擦除可编程只读存储器EPROM、闪速存储器Flash Memory和固态硬盘Solid State Drivers。  
+ 掩模式只读存储器  
MROM的内容由半导体制造厂按照用户提出的要求在芯片的生产过程中直接写入，写入后任何人都无法改变其内容。优点是可靠性高，集成度高，价格便宜；缺点是灵活性差。  
+ 一次可编程只读存储器  
PROM是可以实现一次性编程的只读存储器。允许用户利用专门的设备（编程器）写入自己的程序，一旦写入，内容就无法改变。  
+ 可擦除可编程只读存储器  
EPROM不仅可以由用户利用编程器写入信息，而且可以对其内容进行多次改写。需要修改EPROM的内容时，先将其全部内容擦除，然后编程。EPROM可分为两个，即紫外线擦除UVEPROM和电擦除E<sup>2</sup>PROM。EPROM虽然既可读又可写，但它不能取代RAM，因为EPROM的编程次数有限，且写入时间过长。  
+ 闪速存储器  
Flash Memory是在EPROM和E<sup>2</sup>PROM的基础上发展起来的，其主要特点是既可在不加电的情况下长期保存信息，又能在线进行快速擦除与重写。闪存存储器既有EPROM的价格便宜、集中度高的优点，又有E<sup>2</sup>PROM电可擦除重写的特点，且擦除重写的速度快。  
+ 固态硬盘  
基于闪存的固态硬盘是用固态电子存储芯片阵列制成的硬盘，由控制单元和存储单元FLASH芯片组成。保留了Flash Memory长期保存信息、快速擦除和重写的特性。对比传统硬盘也具有读写速度快、低功耗的特性，缺点是价格较高。  
### 主存储器的基本组成  
主存储器是由一个个的记忆单元（存储元件）构成的存储矩阵（也称存储体）是存储器的核心部分。记忆单元是具有两种稳态的能表示二进制0和1的物理器件。为了存取存储体中的信息，必须对存储单元编号（也称编址）。编制单位是指具有相同地址的那些存储元件构成的一个单位，可以按字节编址，也可以按字编址。现代计算机通常采用字节编址方式，此时存储体内的一个地址中有1字节。  
指令执行过程中需要访问主存时，CPU首先把被访问单位的地址送到MAR中，然后通过地址线（单向）将主存地址送到主存中的地址寄存器，以便地址译码器进行译码选中相应单元，同时CPU将读写信号通过控制线送到主存的读写控制电路。如果是写操作，那么CPU同时将要写的信息送到MDR中，在读写控制逻辑电路的控制下，经数据线（双向）将信号写入选中的单元；如果是读操作，那么主存读出选中单元的内容到数据线，然后送到MDR中。**数据线的宽度与MDR的宽度相同，地址线的宽度与MAR的宽度相同。**  

---  
## 主存储器与CPU的连接  
### 连接原理  
+ 主存储器通过数据总线、地址总线和控制总线与CPU连接  
+ 数据总线的位数与工作频率的乘积正比于数据传输率  
+ 地址总线的位数决定了可寻址空间的最大范围  
+ 控制总线（读/写）指出总线周期的类型和本次输入/输出操作完成的时刻  
### 主存容量的扩展  
由于单个存储芯片的容量是有限的，它在字数或字长方面与实际存储器的要求都有差距，因此需要在字和位两方面进行扩充才能满足实际存储器的容量要求。通常采用位扩展法、字扩展法和字位同时扩展法来扩展主存容量。  
#### 位扩展法  
CPU的数据线数与存储芯片的数据位数不一定相等，此时必须对存储芯片扩位（即进行位扩展，用多个存储器件对字长进行扩充，增加存储字长），使其数据位数与CPU的数据线数相等。  
位扩展的连接方式是将多个存储芯片的地址端、片选端和读写控制端并联，数据端分别引出。  
**片选信号CS需连接到所有芯片**  
#### 字扩展法  
子扩展是指增加存储器中字的数量，而位数不变。字扩展将芯片的地址线、数据线、读写控制线相应并联，而由片选信号来区分各芯片的地址范围。  
**片选信号CS或采用译码器设计连接到需要使用的芯片**  
#### 字位同时扩展法  
实际上，存储器往往需要同时扩充字和位。字位同时扩展是指即增加存储字的数量，又增加存储字长。  
**片选信号CS或采用译码器设计连接到需要使用的芯片**  
### 存储芯片的地址分配和片选  
CPU要实现对存储单元的访问，首先要选择存储芯片，既进行片选；然后为选中的芯片依地址码选择相应的存储单元，以进行数据的存取，即进行字选。片内的字段通常是由CPU送出的N条低位地址线完成的，地址线直接接到所有存储芯片的地址输入端（N由片内存储容量2<sup>N</sup>决定）。片选信号的产生分为线选法和译码片选法。  
#### 线选法  
线选法用除片内寻址外的高位地址线直接（或经反相器）分别接至各个存储芯片的片选端，当某地址线的信息为“0”时，就选中与之对应的存储芯片。这些片选信号线每次寻址时只能一位有效，不允许同时有多位有效，这样才能保证每次只选中一个芯片或芯片组。  
优点：不需要地址译码器，线路简单。  
缺点：地址空间不连续，选片的地址线必须分时为低电平，不能充分利用系统的存储器空间，造成地址资源的浪费。  
#### 译码片选法  
译码片选法用除片内寻址外的高位地址线通过地址译码器芯片产生片选信号。  
### 存储器与CPU的连接  
#### 合理选择存储芯片  
要组成一个系统，选择存储芯片是第一步，主要指存储芯片的类型RAM或ROM和数量的选择。通常选用ROM存放系统程序、标准子程序和各类常数，RAM则是为用户编程而设置的。此外，在考虑芯片数量时，要尽量使连线简单、方便。  
#### 地址线的连接  
存储芯片的容量不同，其地址线数也不同，而CPU的地址线往往比存储芯片的地址线数要多。通常将CPU地址线的低位与存储芯片的地址线相连，以选择芯片中的某一单元（字选），这部分的译码是由芯片的片内逻辑完成的。而CPU地址线的高位则在扩充存储芯片时使用，用来选择存储芯片（片选），这部分译码由外接译码器逻辑完成。  
#### 数据线的连接  
CPU的数据线数与存储芯片的数据线数不一定相等，在相等时可直接相连；在不等时必须对存储芯片扩位，使其数据位数与CPU的数据线数相等。  
#### 读/写命令线的连接  
CPU读/写命令线一般可直接与存储芯片的读/写控制端相连，通常高电平为读，低电平为写。有些CPU的读/写命令线是分开的，均为低电平有效，此时CPU的读命令线应与存储芯片的允许读控制端相连，而CPU的写命令线则应与存储芯片的允许写控制端相连。  
#### 片选线的连接  
片选线的连接是CPU与存储芯片连接的关键。存储器由许多存储芯片叠加而成，哪一片被选中完全取决于该存储芯片的片选控制端CS能否接受到来自CPU的片选有效信号。  
片选有效信号与CPU的访存控制信号<span style="text-decoration:overline">MREQ</span>（低电平有效）有关，因为只有当CPU要求访问时，才要求选中存储芯片。若CPU访问I/O，则<span style="text-decoration:overline">MREQ</span>为高，表示不要求存储器工作。

---
## 双端口RAM和多模块存储器  
为了提高CPU访问存储器的速度，可以采用双端口存储器、多模块存储器等技术，它们同属于并行技术，前者为空间并行，后者为时间并行。  
### 双端口RAM  
双端口RAM是指同一个存储器有左、右两个独立的端口，分别具有两组相互独立的地址线、数据线和读写控制线，允许两个独立的控制器同时异步地访问存储单元。当两个端口的地址不相同时，在两个端口上进行读写操作一定不会发生冲突。  
两个端口同时存取存储器的同一地址单元时，会因数据冲突造成数据存储或读取错误。两个端口对同一主存操作有以下4种情况：  
+ 两个端口不同时对同一地址单元存取数据  
+ 两个端口同时对同一地址单元读出数据  
+ 两个端口同时对同一地址单元写入数据
+ 两个端口同时对同一地址单元操作，一个写入数据，另一个读出数据  

其中，前两种情况不会出现错误，第三种情况会出现写入错误，第四种情况会出现读出错误。  
解决办法：置“忙”信号BUSY为0（低电平有效），由逻辑判断决定暂时关闭一个端口（即被延时），未被关闭的端口正常访问，被关闭的端口延长一个很短的时间段后再访问。  
### 多模块存储器  
为提高访存速度，常采用多模块存储器，常用的有单体多字存储器和多体低位交叉存储器。(CPU的速度比存储器快，若同时从存储器中取出n条指令，就可充分利用CPU资源，提高运行速度。多体交叉存储器就是基于这种思想提出的)。  
#### 单体多字存储器  
单体多字系统的特点是存储器中只有一个存储体，每个存储单元存储m个字，总线宽度也为m个字。一次并行读出m个字，地址必须顺序排列并处于同一个存储单元。  
单体多字系统在一个存取周期内，从一个地址取出m条指令，然后将指令逐条送至CPU执行，即每隔1/m存取周期，CPU向主存取一条指令。显然，这增大了存储器的带宽，提高了单体存储器的工作速度。  
缺点：指令和数据在主存内必须是连续存放的，一旦遇到转移指令，或操作数不能连续存放，这种方法的效果就不明显。  
#### 多体并行存储器  
多体并行存储体由多体模块组成。每个模块都有相同的容量和存取速度，各模块都有独立的读写控制电路、地址寄存器和数据寄存器。它们即能并行工作，又能交叉工作。  
多体并行存储器分为高位交叉编址（顺序方式）和低位交叉编址（交叉方式）两种。  
1. 高位交叉编址：高位体质表示体号，低位地址表示体内地址。  
高位交叉编址方式下，总是把低位的体内地址送到高位体号确定的模块内进行译码。访问一个连续的主存块时，总是先在一个模块内访问，等到该模块访问完才转到下一个模块访问，CPU总是按顺序访问存储模块，存储模块不能被并行访问，**因而不能提高存储器的吞吐率**。  
2. 低位交叉编址：低位地址为体号，高位地址为体内地址。每个模块按“模m”交叉编址，模块号=单位地址%m。  
低位交叉编址方式下，总是把高位的体内地址送到由低位体号确定的模块内进行译码。程序连续存放在相邻模块中，因此称采用此编址方式的存储器为交叉存储器。采用低位交叉编址后，可在不改变每个模块存取周期的前提下，采用流水线的方式并行存取，提高存储器的带宽。  
设模块字长等于数据总线宽度，模块存取一个字的存取周期为T，总线传送周期为r,为实现流水线方式存取，存储器交叉模块数应大于等于`m=T/r`  
式中，m称为交叉存取度。每经过r时间延迟后启动下一模块，交叉存储器要求其模块数必须大于等于m，以保证启动某模块后经过m×r的时间后再次启动该模块时，其上次的存取操作已经完成（即流水线不间断）。这样，连续存取m个字所需的时间为t<sub>1</sub>=T+(m-1)r  
而顺序方式连续读取m个字所需要的时间为t<sub>2</sub>=mT。可见低位交叉存储器的带宽大大提高。  

---  
## 高速缓冲存储器  
由于程序转移概率不会很低，数据分布的离散性较大，所以单纯依靠并行主存系统提高主存系统的频宽是有限的。这就必须从系统结构上进心改进，即采用存储体系。通常将存储系统分为“Cache-主存”层次和“主存-辅存”层次。  
### 程序访问的局部性原理  
程序访问的局部性原理包括时间局部性和空间局部性。时间局部性是指在最近的未来要用到的信息，很可能是现在正在使用的信息，因为程序中存在循环。空间局部性是指在最近的未来要用到的信息，很可能是现在正在使用的信息在存储空间上是邻近的，因为指令通常是顺序存放、顺序执行的，数据一般也是以向量、数组等形式簇聚地存储在一起的。  
高速缓冲技术就是利用程序访问的局部性原理，把程序中正在使用的部分存放在一个高速的、容量较小的Cache中，使CPU的访存操作大多数针对Cache进行，从而大大提高程序的执行速度。  
### Cache的基本工作原理  
Cache位于存储器层析的顶层，通常由SRAM构成。  
为便于Cache和主存之间交换信息，Cache和主存被**划分为相等的块**，Cache块又称Cache行，每块由若干字节组成，块的长度称为块长（Cache行长）。由于Cache的容量远小于主存的容量，所以Cache的块数要远少于主存中的块数，它仅保存主存中最活跃的若干块的**副本**。因此Cache按照某种策略，预测CPU在未来一段时间内欲访问的数据，将其装入Cache。  
当CPU发出读请求时，若访存地址在Cache中命中，就将此地址转换为Cache地址，直接对Cache进行读操作，与主存无关；若Cache不命中，则仍需要访问主存，并将此字所在的块一次性地从主存调入Cache。若此时Cache已满，则需根据某种替换算法，用这个块替换Cache中原来的某块信息。**CPU和Cache之间的数据交换以字为单位，而Cache与主存之间的数据交换则以Cache块为单位。**  
当CPU发出写请求时，若Cache命中，有可能遇到Cache与主存内容不一致的问题。如仅修改Cache中的变量值，主存中仍为原来的变量值。所以若Cache命中，需要按照一定的写策略处理，常见的处理方式有全写法和写回法。  
CPU欲访问的信息已在Cache中的比率称为Cache的命中率。设一个程序执行期间，Cache的命中次数为N<sub>c</sub>，访问主存的总次数为N<sub>m</sub>，则命中率H为  
H = N<sub>c</sub> / (N<sub>c</sub> + N<sub>m</sub>)  
可见为提高访问效率，命中率H越接近1越好。设t<sub>c</sub>为命中时的Cache访问时间，t<sub>m</sub>为未命中时的访问时间，1-H表示未命中率，则Cache主存系统的平均访问时间T<sub>a</sub>为  
T<sub>a</sub> = Ht<sub>c</sub> + (1 - H) t<sub>m</sub>  
### Cache和主存的映射方式  
Cache行中的信息是主存中某个块的副本，地址映射是指把主存地址空间映射到Cache地址空间，即把存放在主存中的信息按照某种规则装入Cache。  
由于Cache行数比主存块数少得多，因此主存中只有一部分块的信息可以存放在Cache中，因此在Cache中要为每块加一个标记，指明它是主存哪一块的副本。该标记的内容相当于主存块中块的编号。为了说明Cache行中的信息是否有效，每个Cache行需要一个有效位。  
地址映射不同于地址变换。地址变换是指CPU在访存时，将主存地址按映射规则换算成Cache地址的过程。地址映射的方法有以下三种：  
#### 直接映射  
主存中的每一块只能装入Cache中的唯一位置。挼这个位置已有内容，则产生块冲突，原来的块无条件地被替换出去。直接映射实现简单，但不够灵活，即使Cache得其他许多地址空着也不能被占用，这使得直接映射地址的块冲突概率最高，空间利用率最低。  
直接映射的关系可定义为j=i mod 2<sup>c</sup>  
式中，j是Cache的块号（又称Cache行号），i是主存的块号，2<sup>c</sup>是Cache中的总块数。由映射函数可看出，主存块号的低c位正好是它要装入的Cache行号。给每个Cache行设置一个长为`t=m-c`的标记（tag），当主存某块调入Cache后，就将其块号的高t位设置在对应Cache行的标记中，直接映射的地址结构为：  

|t位|c位|b位|
|---|---|---|
|标记|Cache行号|块内地址|  

CPU访存过程：首先根据访存地址中间的c位，直接找到对应的Cache行，将对应Cache行中标记和主存地址的高t位进行比较，若相等且有效位为1,则访问Cache命中，此时根据主存地址中低位的块内地址，在对应的Cache行中存取信息；若不相等或有效位为0,则不命中，此时Cache从主存中读出该地址所在的一块信息送到对应的Cache中，将有效位置为1,并将标记设置为地址中的高t位，同时将该地址中的内容送到CPU。  
#### 全相联映射  
主存中的每一块可以装入Cache中的任何位置，每行的标记用于指出该行取自主存的哪一块，所以CPU访存时需要与所有的Cache行的标记进行比较。全相联映射方式的优点是比较灵活，Cache块的冲突概率低，空间利用率高，命中率也高；缺点是标记的比较速度较慢，实现成本较高，通常需采用昂贵的按内容寻址的相联存储器进行地址映射。  
全相联映射的地址结构为  

|标记|块内地址|  
|---|---|  

#### 组相联映射  
将Cache空间分成大小相同的组，主存的一个数据块可以装入一组内的任何一个位置，即组间采用直接映射，而组内采用全相联映射。它是对直接映射和全相联映射的一种折中，当Q=1时变为全相联映射，当Q=Cache块数时变为直接映射。假设每组有r个Cache行，则称之为r路组相联，组相联映射的关系可以定义为  
j=i mod Q  
式中，j是Cache行的组号，i是主存的块号，Q是Cache的组数。  
路数越大，即每组Cache行的数量越大，发生块冲突的概率越低，但相联比较电路也越复杂。选定适当的数量，可使组相联映射的成本接近直接映射，而性能上接近全相联映射。  
组相联映射的地址结构为  
|标记|Cache组号|块内地址|  
|---|---|---|  

CPU访存过程如下：首先根据访存地址中间的组号找到对应的Cache组；将对应Cache组中的每个行的标记与主存地址的高位标记进行比较；若有一个相等且有效位为1,则访问Cache命中，此时根据主存地址中的块内地址，在对应Cache行中存取信息；若都不相等或虽相等但有效位为0,则不命中，此时CPU从主存中读出该地址所在的一块信息送到对应Cache组的任意一个空闲行中，将有效位置为1,并设置标记，同时将该地址中的内容送至CPU。  
三种映射方式中，直接映射的每个主存块只能映射到Cache中的某一固定行；全相联映射可以映射到所有Cache行；N路组相联映射可以映射到N行，当Cache太小、主存块大小一定时：  
+ 直接映射的命中率最低，全相联映射的命中率最高  
+ 直接映射的判断开销最小、所需时间最短，全相联映射的映射开销最大、所需时间最长  
+ 直接映射标记所占的额外空间开销最小，全相联映射标记所占的额外空间开销最大  
### Cache中主存块的替换算法  
在采用全相联映射或组相联映射方式时，从主存向Cache传送一个新块，当Cache或Cache组中的空间已被占满时，就需要使用替换算法置换Cache行。而采用直接映射时，一个给定的主存块只能放到唯一的固定Cache行中，所以在对应Cache行已有一个主存块的情况下，新的主存块毫无选择地把原先已有的那个主存块替换掉，因而无须考虑替换算法。  
常用的替换算法有  
+ 随机（RAND）算法。随机地确定替换的Cache块，实现比较简单，但未考虑程序访问的局部性原理，因此可能命中率较低。  
+ 先进先出（FIFO）算法。选择最早调入的行进行替换。比较容易实现，但也为考虑程序访问的局部性原理，因为最早进入的主存块也可能是目前经常使用的。  
+ 近期最少使用（LRU）算法。依据程序局部性原理，选择近期内长久未访问过的Cache行作为替换的行，平均命中率要比FIFO的高，是堆栈类算法。  
+ 最不经常使用（LFU）算法。将一段时间内被访问次数最少的存储行换出。每行设置一个计数器，新行建立后从0开始计数，每访问一次，被访问的行计数器加1，需要替换时比较各特定行的计数值，将计数值最小的行换出。  
